# -*- coding: utf-8 -*-
"""Predictor de cancer de pulmon.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WX6nqQXa6asMtQmqTLMbjppykn_G_TC5

# Predictor de cancer de pulmon
Proyecto Adamaris y Cristobal \\
Lung Cancer Prediction \\
data: https://www.kaggle.com/datasets/mysarahmadbhat/lung-cancer/

#Preparación de la base de datos

Librerias
"""

import pandas as pd
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
from sklearn.svm import SVC
from sklearn.model_selection import RandomizedSearchCV
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import RandomOverSampler
from traitlets.traitlets import default
from sklearn.neural_network import MLPClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn import metrics

"""Visualización de los primeros datos"""

df = pd.read_csv('lungcancer.csv')
df.head()

df.info()

"""Reemplazamos los valores de la base de datos para tener todo en terminos de 0 y 1"""

df = df.replace(1,0)
df = df.replace(2,1)

df['LUNG_CANCER'] = df['LUNG_CANCER'].replace('YES', 1)
df['LUNG_CANCER'] = df['LUNG_CANCER'].replace('NO', 0)

df['GENDER'] = df['GENDER'].replace('M', 1)
df['GENDER'] = df['GENDER'].replace('F', 0)

df.head(10)

"""Estadisticas descriptivas para analisis inicial"""

df.describe()

"""Eliminamos los valores duplicados"""

df.duplicated().sum()

df.drop_duplicates(inplace=True)

"""Estandarizamos la base de datos

"""

df = df/df.max()
df.head()

"""Seleccionamos ejemplos aleatorios para evitar overfitting"""

X=df.drop(['LUNG_CANCER'],axis=1)
y=df['LUNG_CANCER']

X_over,y_over=RandomOverSampler().fit_resample(X,y)

"""Dividimos nuestros datos en un conjunto de prueba y otro de entrenamiento"""

X_train,X_test,y_train,y_test = train_test_split(X_over,y_over,random_state=42,stratify=y_over)
print(f'Train shape : {X_train.shape}\nTest shape: {X_test.shape}')

"""Mapa de correlación"""

fig = plt.figure(figsize=(30,15))
sns.heatmap(df.corr(), cmap="crest",annot=True, linewidth=0.5)
plt.show()

"""#Modelos

KNN
"""

knn_scores=[]
for k in range(1,20):
    knn=KNeighborsClassifier(n_neighbors=k)
    scores=cross_val_score(knn,X_train,y_train,cv=5)
    knn_scores.append(scores.mean())

x_ticks = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]
x_labels = x_ticks

plt.plot([k for k in range(1,20)],knn_scores)
plt.xticks(ticks=x_ticks, labels=x_labels)
plt.grid()

knn=KNeighborsClassifier(n_neighbors=1)
knn.fit(X_train,y_train)
from sklearn.metrics import confusion_matrix
confusion_knn=confusion_matrix(y_test,knn.predict(X_test))
plt.figure(figsize=(8,8))
sns.heatmap(confusion_knn,annot=True)
plt.xlabel("Predicted")
plt.ylabel("Actual")
from sklearn.metrics import classification_report
print(classification_report(y_test,knn.predict(X_test)))

"""SVM"""

param_grid={'C':[0.001,0.01,0.1,1,10,100], 'gamma':[0.001,0.01,0.1,1,10,100]}
rcv=RandomizedSearchCV(SVC(),param_grid,cv=5)
rcv.fit(X_train,y_train)
y_pred_svc=rcv.predict(X_test)
confusion_svc=confusion_matrix(y_test,rcv.predict(X_test))
plt.figure(figsize=(8,8))
sns.heatmap(confusion_svc,annot=True)
plt.xlabel("Predicted")
plt.ylabel("Actual")
print(classification_report(y_test,y_pred_svc))
print(f'\nBest Parameters of SVC model is : {rcv.best_params_}\n')

"""Random forest"""

param_grid = {'n_estimators': [50, 75,100, 150, 200,300],}
rcv=RandomizedSearchCV(RandomForestClassifier(random_state=42),param_grid,cv=5)
rcv.fit(X_train,y_train)
y_pred_rcv=rcv.predict(X_test)
confusion_rcv=confusion_matrix(y_test,rcv.predict(X_test))
plt.figure(figsize=(8,8))
sns.heatmap(confusion_rcv,annot=True)
plt.xlabel("Predicted")
plt.ylabel("Actual")
print(classification_report(y_test,y_pred_rcv))
print(f'\nBest Parameter: {rcv.best_params_}\n')

"""#DecisionTreeClassifier"""

df.head()

clf = DecisionTreeClassifier()
clf = clf.fit(X_train,y_train)
y_pred = clf.predict(X_test)
feature_cols = ['Gender', 'AGE', 'SMOKING', 'YELLOW_FINGERS','ANXIETY', 'PEER_PRESSURE', 'CHRONIC DISEASE', 'FATIGUE', 'ALLERGY', 'WHEEZING', 'ALCOHOL CONSUMING', 'COUGHING', 'SHORTNESS OF BREATH', 'SWALLOWING DIFFICULTY', 'CHEST PAIN']

print("Accuracy:",metrics.accuracy_score(y_test, y_pred))

confusion_svc=confusion_matrix(y_test,y_pred)
plt.figure(figsize=(8,8))
sns.heatmap(confusion_svc,annot=True)
plt.xlabel("Predicted")
plt.ylabel("Actual")
print(classification_report(y_test,y_pred))

from sklearn.tree import export_graphviz
from six import StringIO
from IPython.display import Image
import pydotplus

dot_data = StringIO()
export_graphviz(clf, out_file=dot_data,
                filled=True, rounded=True,
                special_characters=True,feature_names = feature_cols,class_names=['0','1'])
graph = pydotplus.graph_from_dot_data(dot_data.getvalue())
graph.write_png('LungC.png')
Image(graph.create_png())

"""SVC (C-Support Vector Classification)"""

model = SVC(gamma=10,C=100)
model.fit(X_train,y_train)
y_pred_svc=model.predict(X_test)
confusion_svc=confusion_matrix(y_test,y_pred_svc)
plt.figure(figsize=(8,8))
sns.heatmap(confusion_svc,annot=True)
plt.xlabel("Predicted")
plt.ylabel("Actual")
print(classification_report(y_test,y_pred_svc))

"""MLP Classifier"""

model = MLPClassifier(hidden_layer_sizes=(50, ), max_iter=500, alpha=1e-4, solver='sgd', verbose=10,random_state=54,learning_rate='adaptive',).fit(X_train,y_train)
print(model.score(X_train,y_train))

"""#PCA
Estimador de aprendizaje no supervisado.
 PCA is fundamentally a
dimensionality reduction algorithm, but it can also be useful as a tool for visualization, for noise filtering, for feature extraction and engineering, and much more.
"""

pca = PCA(n_components=1)
pca.fit(X)

df.head()

pca.components_

print(pca.explained_variance_)

pca.explained_variance_ratio_

pca_df = df[['GENDER','YELLOW_FINGERS','ANXIETY','ALCOHOL CONSUMING','PEER_PRESSURE','LUNG_CANCER']].copy()
pca_df.head()

X=pca_df.drop(['LUNG_CANCER'],axis=1)
y=pca_df['LUNG_CANCER']

X_over,y_over=RandomOverSampler().fit_resample(X,y)

X_train,X_test,y_train,y_test = train_test_split(X_over,y_over,random_state=42,stratify=y_over)
print(f'Train shape : {X_train.shape}\nTest shape: {X_test.shape}')

"""DecisionTreeClassifier"""

clf = DecisionTreeClassifier(max_depth=4)
clf = clf.fit(X_train,y_train)
y_pred = clf.predict(X_test)
feature_cols = ['GENDER','YELLOW_FINGERS','ANXIETY','ALCOHOL CONSUMING','PEER_PRESSURE', 'SMOKING']

print("Accuracy:",metrics.accuracy_score(y_test, y_pred))

dot_data = StringIO()
export_graphviz(clf, out_file=dot_data,
                filled=True, rounded=True,
                special_characters=True,feature_names = feature_cols,class_names=['0','1'])
graph = pydotplus.graph_from_dot_data(dot_data.getvalue())
graph.write_png('LungC.png')
Image(graph.create_png())

confusion_svc=confusion_matrix(y_test,y_pred)
plt.figure(figsize=(8,8))
sns.heatmap(confusion_svc,annot=True)
plt.xlabel("Predicted")
plt.ylabel("Actual")
print(classification_report(y_test,y_pred))